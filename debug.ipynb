{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from equiformer_pytorch import Equiformer\n",
    "\n",
    "\n",
    "def get_toy_model():\n",
    "    model = Equiformer(\n",
    "        dim_in=(20, 3),\n",
    "        input_degrees=2,\n",
    "        dim = (4, 4, 2),      \n",
    "        dim_head = (4, 4, 4), \n",
    "        heads = (2, 2, 2),    \n",
    "        num_degrees = 3,      \n",
    "        reduce_dim_out = False,\n",
    "        num_neighbors=1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_toy_input(coors_mask=torch.tensor([0, 0, 0]).float()):\n",
    "    # 1 batch with 5 points stacked on top of each other in 3D with \n",
    "    # 20 random type-0 and 3 random type-1 features + 2 padding points\n",
    "    # with random features and coors set to `coors_mask`.\n",
    "    feats = {\n",
    "        0: torch.randn(1, 7, 20, 1),\n",
    "        1: torch.randn(1, 7, 3, 1)\n",
    "    }\n",
    "    coors = torch.tensor([[[0, 0, 0], [0, 0, 1], [0, 0, 2], [0, 0, 3], [0, 0, 4], coors_mask.detach(), coors_mask.detach()]]).float()\n",
    "    mask  = torch.tensor([[1, 1, 1, 1, 1, 0, 0]]).bool()\n",
    "    return feats, coors, mask\n",
    "\n",
    "\n",
    "def train_toy(model, feats, coors, mask):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "    for _ in range(2):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(feats, coors, mask)\n",
    "        print('out.type0[mask]', out.type0[mask])\n",
    "        loss = out.type0[mask].sum().norm() # dummy loss through type-0 features\n",
    "        print('loss', loss)\n",
    "        print()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeInfo(neighbor_indices=tensor([[[5],\n",
      "         [0],\n",
      "         [1],\n",
      "         [2],\n",
      "         [3],\n",
      "         [0],\n",
      "         [0]]]), neighbor_mask=tensor([[[False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False]]]), edges=None)\n",
      "out.type0[mask] tensor([[-0.5886, -0.5910, -0.7438,  1.6586],\n",
      "        [-1.2187,  1.0213,  0.3353, -1.1659],\n",
      "        [-1.6366,  0.5513, -0.6860, -0.7395],\n",
      "        [ 0.3319,  0.4592,  0.0487,  1.9175],\n",
      "        [-1.2321,  1.1638,  0.2361, -1.0353]], grad_fn=<IndexBackward0>)\n",
      "loss tensor(1.9140, grad_fn=<NormBackward1>)\n",
      "\n",
      "EdgeInfo(neighbor_indices=tensor([[[5],\n",
      "         [0],\n",
      "         [1],\n",
      "         [2],\n",
      "         [3],\n",
      "         [0],\n",
      "         [0]]]), neighbor_mask=tensor([[[False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False]]]), edges=None)\n",
      "out.type0[mask] tensor([[-0.4579, -0.4649, -0.6095,  1.7904],\n",
      "        [-1.3384,  1.0126,  0.4569, -0.9824],\n",
      "        [-1.6434,  0.8028, -0.3073, -0.7352],\n",
      "        [ 0.7429,  0.9579,  0.1811,  1.5814],\n",
      "        [-1.1874,  1.2502,  0.3536, -0.9481]], grad_fn=<IndexBackward0>)\n",
      "loss tensor(0.4554, grad_fn=<NormBackward1>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "# Below, the expected 1-NN grpah creates dummy edge with padded token for node 0\n",
    "# instead of the edge to the closest node 1.\n",
    "model = get_toy_model()\n",
    "feats, coors, mask = get_toy_input()\n",
    "train_toy(model, feats, coors, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeInfo(neighbor_indices=tensor([[[1],\n",
      "         [0],\n",
      "         [1],\n",
      "         [2],\n",
      "         [3],\n",
      "         [0],\n",
      "         [0]]]), neighbor_mask=tensor([[[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False]]]), edges=None)\n",
      "out.type0[mask] tensor([[-0.3113, -0.7774, -1.2577,  1.3103],\n",
      "        [ 0.7112,  0.8714,  1.3977, -0.8839],\n",
      "        [-1.6713, -1.0266, -0.2549, -0.2964],\n",
      "        [ 0.8971, -1.1418, -1.3702,  0.1183],\n",
      "        [ 0.7703,  0.1469,  1.8398, -0.0075]], grad_fn=<IndexBackward0>)\n",
      "loss tensor(0.9361, grad_fn=<NormBackward1>)\n",
      "\n",
      "EdgeInfo(neighbor_indices=tensor([[[1],\n",
      "         [0],\n",
      "         [1],\n",
      "         [2],\n",
      "         [3],\n",
      "         [0],\n",
      "         [0]]]), neighbor_mask=tensor([[[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False]]]), edges=None)\n",
      "out.type0[mask] tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], grad_fn=<IndexBackward0>)\n",
      "loss tensor(nan, grad_fn=<NormBackward1>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# So, the expected would be to set padded coords to inf not to be considered as nearest to any node.\n",
    "# but it then leads to NaN loss.\n",
    "model = get_toy_model()\n",
    "feats, coors, mask = get_toy_input(coors_mask=torch.tensor([float('inf'), float('inf'), float('inf')]).float())\n",
    "train_toy(model, feats, coors, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeInfo(neighbor_indices=tensor([[[1],\n",
      "         [0],\n",
      "         [1],\n",
      "         [2],\n",
      "         [3],\n",
      "         [0],\n",
      "         [0]]]), neighbor_mask=tensor([[[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False]]]), edges=None)\n",
      "out.type0[mask] tensor([[-0.0844,  1.4477, -1.3534, -0.2554],\n",
      "        [-1.4856, -0.7888,  1.0603, -0.2158],\n",
      "        [-0.0585,  0.4015, -1.6796, -1.0071],\n",
      "        [ 0.9682,  1.1221, -0.7594,  1.1076],\n",
      "        [-0.3963,  0.5135, -1.0182,  1.5945]], grad_fn=<IndexBackward0>)\n",
      "loss tensor(0.8872, grad_fn=<NormBackward1>)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: Error detected in MulBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/yw/q5k8tqgn3tq8_y9lbqhwm_8m0000gn/T/ipykernel_29267/261394536.py\", line 4, in <module>\n",
      "    train_toy(model, feats, coors, mask)\n",
      "  File \"/var/folders/yw/q5k8tqgn3tq8_y9lbqhwm_8m0000gn/T/ipykernel_29267/1731602763.py\", line 36, in train_toy\n",
      "    out = model(feats, coors, mask)\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/anton/dev/equiformer-pytorch/equiformer_pytorch/equiformer_pytorch.py\", line 1190, in forward\n",
      "    x = self.norm(x)\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/anton/dev/equiformer-pytorch/equiformer_pytorch/equiformer_pytorch.py\", line 211, in forward\n",
      "    output[degree] = t / rms.clamp(min = self.eps) * scale\n",
      "  File \"/Users/anton/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/torch/fx/traceback.py\", line 57, in format_stack\n",
      "    return traceback.format_stack()\n",
      " (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:119.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'MulBackward0' returned nan values in its 1th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m get_toy_model()\n\u001b[1;32m      3\u001b[0m feats, coors, mask \u001b[39m=\u001b[39m get_toy_input(coors_mask\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor([\u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)])\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m----> 4\u001b[0m train_toy(model, feats, coors, mask)\n",
      "Cell \u001b[0;32mIn[48], line 41\u001b[0m, in \u001b[0;36mtrain_toy\u001b[0;34m(model, feats, coors, mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m---> 41\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     42\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ppiformer_m1/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'MulBackward0' returned nan values in its 1th output."
     ]
    }
   ],
   "source": [
    "# 3\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    model = get_toy_model()\n",
    "    feats, coors, mask = get_toy_input(coors_mask=torch.tensor([float('inf'), float('inf'), float('inf')]).float())\n",
    "    train_toy(model, feats, coors, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppiformer_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
